import os
import tempfile
import math
import logging
import asyncio
from pydub import AudioSegment
from openai import OpenAI
from models.schemas import TranscriptionResult, TranscriptionSegment

logger = logging.getLogger(__name__)

# å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã€å¿…è¦æ™‚ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
def get_progress_manager():
    from services.progress_manager import progress_manager
    return progress_manager

class TranscriptionService:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    async def transcribe(self, audio_file_path: str, session_id: str = "default") -> TranscriptionResult:
        """
        OpenAI Whisper APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹
        å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆ†å‰²ã—ã¦å‡¦ç†ã™ã‚‹
        """
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
            file_size = os.path.getsize(audio_file_path)
            max_size = 25 * 1024 * 1024  # 25MB

            if file_size <= max_size:
                # å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯ç›´æ¥å‡¦ç†
                return await self._transcribe_single_file(audio_file_path, session_id)
            else:
                # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆ†å‰²ã—ã¦å‡¦ç†
                return await self._transcribe_large_file(audio_file_path, session_id)
        except Exception as e:
            raise Exception(f"Transcription failed: {str(e)}")

    async def _transcribe_single_file(self, audio_file_path: str, session_id: str) -> TranscriptionResult:
        """
        å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ï¼ˆç–‘ä¼¼é€²æ—ä»˜ãï¼‰
        """
        progress_manager = get_progress_manager()

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’å–å¾—ã—ã¦æ¨å®šæ™‚é–“ã‚’è¨ˆç®—
        audio = AudioSegment.from_file(audio_file_path)
        duration_seconds = len(audio) / 1000.0

        # éŸ³å£°ã®é•·ã•ã«åŸºã¥ã„ã¦æ¨å®šå‡¦ç†æ™‚é–“ã‚’è¨ˆç®—ï¼ˆRTF=0.07ã‚’ä½¿ç”¨ï¼‰
        estimated_time = duration_seconds * 0.07

        await progress_manager.update_progress(session_id, "transcribing", 15, f"éŸ³å£°èªè­˜ã‚’é–‹å§‹ï¼ˆæ¨å®šæ™‚é–“: {estimated_time:.1f}ç§’ï¼‰...")

        # ç–‘ä¼¼é€²æ—ã‚’é–‹å§‹
        progress_task = asyncio.create_task(
            self._simulate_transcription_progress(session_id, estimated_time, progress_manager)
        )

        try:
            # å®Ÿéš›ã®éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œ
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    response_format="verbose_json"
                )
        finally:
            # ç–‘ä¼¼é€²æ—ã‚’åœæ­¢
            progress_task.cancel()
            try:
                await progress_task
            except asyncio.CancelledError:
                pass

        await progress_manager.update_progress(session_id, "transcription_complete", 75, "éŸ³å£°èªè­˜å®Œäº†")

        return self._process_transcript(transcript)

    async def _simulate_transcription_progress(self, session_id: str, estimated_time: float, progress_manager):
        """
        éŸ³å£°èªè­˜ä¸­ã®ç–‘ä¼¼é€²æ—ã‚’è¡¨ç¤º
        """
        try:
            # é€²æ—æ®µéšã‚’å®šç¾©ï¼ˆ15%ã‹ã‚‰75%ã¾ã§ï¼‰
            progress_stages = [
                (20, "éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­..."),
                (25, "éŸ³å£°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èªè­˜ä¸­..."),
                (35, "å˜èªã‚’è­˜åˆ¥ä¸­..."),
                (45, "æ–‡ç« ã‚’æ§‹ç¯‰ä¸­..."),
                (55, "æ–‡è„ˆã‚’è§£æä¸­..."),
                (65, "æœ€çµ‚èª¿æ•´ä¸­..."),
                (70, "éŸ³å£°èªè­˜ã‚’å®Œäº†ä¸­...")
            ]

            # å„æ®µéšã®é–“éš”ã‚’è¨ˆç®—
            total_stages = len(progress_stages)
            interval = estimated_time / total_stages if estimated_time > 0 else 2.0

            # æœ€å°ãƒ»æœ€å¤§é–“éš”ã‚’è¨­å®š
            interval = max(1.0, min(interval, 5.0))

            for progress, message in progress_stages:
                await asyncio.sleep(interval)
                await progress_manager.update_progress(session_id, "transcribing", progress, message)

        except asyncio.CancelledError:
            # ã‚¿ã‚¹ã‚¯ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚ŒãŸå ´åˆï¼ˆæ­£å¸¸çµ‚äº†ï¼‰
            pass
        except Exception as e:
            logger.error(f"Progress simulation error: {e}")

    async def _simulate_segment_progress(self, session_id: str, start_progress: int, end_progress: int, estimated_time: float, progress_manager, segment_num: int, total_segments: int):
        """
        ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®ç–‘ä¼¼é€²æ—ã‚’è¡¨ç¤º
        """
        try:
            # é€²æ—ã®ç¯„å›²ã‚’è¨ˆç®—
            progress_range = end_progress - start_progress
            steps = 3  # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’3æ®µéšã§é€²æ—è¡¨ç¤º

            interval = estimated_time / steps if estimated_time > 0 else 1.0
            interval = max(0.5, min(interval, 3.0))

            for step in range(1, steps + 1):
                await asyncio.sleep(interval)
                current_progress = start_progress + int((step / steps) * progress_range)
                await progress_manager.update_progress(
                    session_id,
                    "transcribing",
                    current_progress,
                    f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num}/{total_segments} å‡¦ç†ä¸­... (æ®µéš{step}/{steps})"
                )

        except asyncio.CancelledError:
            pass
        except Exception as e:
            logger.error(f"Segment progress simulation error: {e}")

    async def _transcribe_large_file(self, audio_file_path: str, session_id: str) -> TranscriptionResult:
        """
        å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦æ–‡å­—èµ·ã“ã—
        """
        logger.info(f"Large file detected, starting segmentation: {audio_file_path}")
        progress_manager = get_progress_manager()

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹
        await progress_manager.update_progress(session_id, "loading", 12, "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        logger.info(f"Loading audio file: {audio_file_path}")
        audio = AudioSegment.from_file(audio_file_path)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
        actual_duration_ms = len(audio)
        actual_duration_seconds = actual_duration_ms / 1000.0
        actual_duration_minutes = actual_duration_seconds / 60.0

        logger.info(f"Audio file loaded successfully:")
        logger.info(f"  Duration: {actual_duration_ms}ms ({actual_duration_seconds:.1f}s, {actual_duration_minutes:.1f}min)")
        logger.info(f"  Sample rate: {audio.frame_rate}Hz")
        logger.info(f"  Channels: {audio.channels}")
        logger.info(f"  Sample width: {audio.sample_width} bytes")

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚å‡ºåŠ›
        print(f"ğŸµ AUDIO DEBUG INFO:")
        print(f"  Duration: {actual_duration_ms}ms ({actual_duration_seconds:.1f}s, {actual_duration_minutes:.1f}min)")
        print(f"  Sample rate: {audio.frame_rate}Hz")
        print(f"  Channels: {audio.channels}")
        print(f"  Sample width: {audio.sample_width} bytes")

        await progress_manager.update_progress(session_id, "preparing", 15, f"éŸ³å£°åˆ†å‰²ã®æº–å‚™ä¸­... (éŸ³å£°æ™‚é–“: {actual_duration_minutes:.1f}åˆ†)")

        print(f"ğŸ”§ [SEGMENTATION] åˆ†å‰²æº–å‚™é–‹å§‹")

        # åˆ†å‰²è¨­å®šï¼ˆ25MBåˆ¶é™ã‚’ç¢ºå®Ÿã«ä¸‹å›ã‚‹ã‚ˆã†ã«èª¿æ•´ï¼‰
        segment_duration = 2 * 60 * 1000  # 2åˆ†ï¼ˆãƒŸãƒªç§’ï¼‰
        overlap_duration = 15 * 1000      # 15ç§’ã®é‡è¤‡ï¼ˆãƒŸãƒªç§’ï¼‰

        # åˆ†å‰²æ•°ã‚’è¨ˆç®—
        total_duration = len(audio)
        num_segments = math.ceil(total_duration / segment_duration)

        print(f"ğŸ“Š [SEGMENTATION] åˆ†å‰²è¨ˆç”»:")
        print(f"  ç·æ™‚é–“: {total_duration}ms ({total_duration/1000/60:.1f}åˆ†)")
        print(f"  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·: {segment_duration}ms ({segment_duration/1000:.0f}ç§’)")
        print(f"  é‡è¤‡æ™‚é–“: {overlap_duration}ms ({overlap_duration/1000:.0f}ç§’)")
        print(f"  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {num_segments}")

        logger.info(f"Audio duration: {total_duration/1000:.1f}s ({total_duration/1000/60:.1f} minutes)")
        logger.info(f"Segment duration: {segment_duration/1000:.1f}s, Overlap: {overlap_duration/1000:.1f}s")
        logger.info(f"Will create {num_segments} segments")

        await progress_manager.update_progress(
            session_id,
            "segmenting",
            18,
            f"éŸ³å£°ã‚’{num_segments}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã™ï¼ˆç·æ™‚é–“: {total_duration/1000/60:.1f}åˆ†ï¼‰"
        )

        # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ï¼ˆé †ç•ªã‚’æ˜ç¢ºã«ç®¡ç†ï¼‰
        transcripts = []
        temp_files = []

        print(f"ğŸš€ [SEGMENTATION] ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†é–‹å§‹ ({num_segments}å€‹)")

        try:
            for i in range(num_segments):
                segment_index = i  # æ˜ç¢ºãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†

                print(f"ğŸ”„ [SEGMENTATION] ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_index+1}/{num_segments} é–‹å§‹")

                try:  # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å‡¦ç†ã‚’å€‹åˆ¥ã«try-catch
                    print(f"ğŸ”„ Processing segment {segment_index+1}/{num_segments}")

                    # åˆ†å‰²å‡¦ç†ã®é€²æ—ï¼ˆ10%ã‹ã‚‰15%ã®ç¯„å›²ï¼‰
                    segment_progress = 10 + int((segment_index / num_segments) * 5)
                    await progress_manager.update_progress(
                        session_id,
                        "splitting",
                        segment_progress,
                        f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_index+1}/{num_segments} ã‚’åˆ‡ã‚Šå‡ºã—ä¸­... (æ®‹ã‚Š{num_segments-segment_index-1}å€‹)"
                    )

                    logger.info(f"Processing segment {segment_index+1}/{num_segments} (index: {segment_index})")

                    start_time = segment_index * segment_duration
                    end_time = min(start_time + segment_duration + overlap_duration, total_duration)

                    print(f"âœ‚ï¸ [SEGMENTATION] ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_index+1} æ™‚é–“: {start_time/1000:.1f}s - {end_time/1000:.1f}s")
                    logger.info(f"Segment {segment_index+1}: {start_time/1000:.1f}s - {end_time/1000:.1f}s")

                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ‡ã‚Šå‡ºã—
                    print(f"ğŸµ [SEGMENTATION] éŸ³å£°åˆ‡ã‚Šå‡ºã—ä¸­...")
                    segment = audio[start_time:end_time]
                    print(f"âœ… [SEGMENTATION] éŸ³å£°åˆ‡ã‚Šå‡ºã—å®Œäº†")

                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
                    segment_duration_seconds = len(segment) / 1000.0
                    logger.info(f"Segment {segment_index+1} duration: {segment_duration_seconds:.1f}s")

                    if segment_duration_seconds < 0.1:
                        logger.warning(f"Segment {segment_index+1} is too short ({segment_duration_seconds:.3f}s), skipping...")
                        continue

                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ç•ªå·ä»˜ãã§ä¿å­˜
                    print(f"ğŸ’¾ [SEGMENTATION] ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
                    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f"_segment_{segment_index:03d}.wav")
                    segment.export(temp_file.name, format="wav")
                    temp_files.append(temp_file.name)
                    print(f"âœ… [SEGMENTATION] ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {temp_file.name}")

                    logger.info(f"Saved segment {segment_index+1} to: {temp_file.name}")

                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèªï¼ˆ25MBåˆ¶é™ï¼‰
                    file_size = os.path.getsize(temp_file.name)
                    max_segment_size = 25 * 1024 * 1024  # 25MB
                    logger.info(f"Segment {segment_index+1} size: {file_size/1024/1024:.1f}MB")

                    if file_size > max_segment_size:
                        raise Exception(f"Segment {segment_index} size ({file_size} bytes) exceeds 25MB limit")

                    # æ–‡å­—èµ·ã“ã—é€²æ—ï¼ˆ15%ã‹ã‚‰78%ã®ç¯„å›²ï¼‰
                    base_progress = 15 + int((segment_index / num_segments) * 63)
                    await progress_manager.update_progress(
                        session_id,
                        "transcribing",
                        base_progress,
                        f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_index+1}/{num_segments} ã‚’æ–‡å­—èµ·ã“ã—ä¸­... ({file_size/1024/1024:.1f}MB)"
                    )

                    # WebSocketé€ä¿¡ã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚ã®çŸ­ã„å¾…æ©Ÿ
                    await asyncio.sleep(0.1)

                    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ»ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
                    logger.info(f"Transcribing segment {segment_index+1}...")
                    print(f"ğŸ¤ [TRANSCRIPTION] ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_index+1} OpenAI APIå‘¼ã³å‡ºã—é–‹å§‹")

                    transcript = None
                    max_retries = 3

                    for retry in range(max_retries):
                        try:
                            print(f"ğŸ”„ [TRANSCRIPTION] APIå‘¼ã³å‡ºã—è©¦è¡Œ {retry+1}/{max_retries}")

                            with open(temp_file.name, "rb") as audio_file:
                                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§APIå‘¼ã³å‡ºã—
                                transcript = await asyncio.wait_for(
                                    asyncio.to_thread(
                                        lambda: self.client.audio.transcriptions.create(
                                            model="whisper-1",
                                            file=audio_file,
                                            response_format="verbose_json"
                                        )
                                    ),
                                    timeout=120.0  # 2åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                                )
                            print(f"âœ… [TRANSCRIPTION] APIå‘¼ã³å‡ºã—æˆåŠŸ")
                            break

                        except asyncio.TimeoutError:
                            print(f"â° [TRANSCRIPTION] APIå‘¼ã³å‡ºã—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (è©¦è¡Œ {retry+1}/{max_retries})")
                            if retry == max_retries - 1:
                                raise Exception(f"OpenAI API timeout after {max_retries} retries")
                            await asyncio.sleep(5)  # 5ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤

                        except Exception as e:
                            print(f"âŒ [TRANSCRIPTION] APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e} (è©¦è¡Œ {retry+1}/{max_retries})")
                            if retry == max_retries - 1:
                                raise
                            await asyncio.sleep(5)  # 5ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤

                    # æ–‡å­—èµ·ã“ã—çµæœã‚’ãƒ­ã‚°å‡ºåŠ›
                    transcript_text = getattr(transcript, 'text', 'No text available')
                    transcript_duration = getattr(transcript, 'duration', (end_time - start_time) / 1000.0)

                    logger.info(f"Segment {segment_index+1} transcription completed:")
                    logger.info(f"  Index: {segment_index}")
                    logger.info(f"  Duration: {transcript_duration:.1f}s")
                    logger.info(f"  Text length: {len(transcript_text)} characters")
                    logger.info(f"  Text preview: {transcript_text[:100]}...")

                    print(f"âœ… Segment {segment_index+1} completed: {len(transcript_text)} chars")

                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå®Œäº†æ™‚ã®é€²æ—æ›´æ–°
                    completed_progress = 15 + int(((segment_index + 1) / num_segments) * 63)
                    await progress_manager.update_progress(
                        session_id,
                        "transcribing",
                        completed_progress,
                        f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_index+1}/{num_segments} å®Œäº† ({len(transcript_text)}æ–‡å­—)"
                    )

                    # WebSocketé€ä¿¡ã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚ã®çŸ­ã„å¾…æ©Ÿ
                    await asyncio.sleep(0.1)

                    transcripts.append({
                        'index': segment_index,  # é †ç•ªæƒ…å ±ã‚’è¿½åŠ 
                        'transcript': transcript,
                        'start_offset': start_time / 1000.0,  # ç§’ã«å¤‰æ›
                        'duration': transcript_duration,
                        'original_start_time': start_time / 1000.0,
                        'original_end_time': end_time / 1000.0
                    })

                except Exception as segment_error:
                    logger.error(f"Error processing segment {segment_index+1}: {segment_error}")
                    print(f"âŒ Error in segment {segment_index+1}: {segment_error}")
                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ã§ã‚‚å‡¦ç†ã‚’ç¶šè¡Œ
                    continue

            # ãƒãƒ¼ã‚¸å‡¦ç†ã®é€²æ—
            await progress_manager.update_progress(session_id, "merging", 78, "æ–‡å­—èµ·ã“ã—çµæœã‚’ãƒãƒ¼ã‚¸ä¸­...")

            # æ–‡å­—èµ·ã“ã—çµæœã‚’ãƒãƒ¼ã‚¸
            logger.info("Merging transcription results...")
            result = self._merge_transcripts(transcripts, overlap_duration / 1000.0)

            await progress_manager.update_progress(session_id, "transcription_complete", 78, "éŸ³å£°èªè­˜å®Œäº†")
            logger.info("Large file transcription completed successfully")
            return result

        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            for temp_file in temp_files:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)
    
    def _merge_transcripts(self, transcripts, overlap_duration: float) -> TranscriptionResult:
        """
        åˆ†å‰²ã•ã‚ŒãŸæ–‡å­—èµ·ã“ã—çµæœã‚’ãƒãƒ¼ã‚¸
        """
        logger.info(f"Merging {len(transcripts)} transcript segments")
        logger.info(f"Overlap duration: {overlap_duration:.1f}s")

        if not transcripts:
            return TranscriptionResult(segments=[], full_text="")

        # é †ç•ªã‚’ç¢ºå®Ÿã«ã‚½ãƒ¼ãƒˆ
        transcripts.sort(key=lambda x: x['index'])
        logger.info("Sorted transcripts by index:")
        for i, t in enumerate(transcripts):
            logger.info(f"  Position {i}: Index {t['index']}, Start: {t['original_start_time']:.1f}s")

        # æ”¹å–„ã•ã‚ŒãŸé‡è¤‡å‡¦ç†ã‚’æœ‰åŠ¹åŒ–
        use_overlap_processing = True  # é‡è¤‡å‡¦ç†ã‚’æœ‰åŠ¹åŒ–
        logger.info(f"Overlap processing: {'enabled' if use_overlap_processing else 'disabled (debug mode)'}")

        # æœ€åˆã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’åŸºæº–ã¨ã™ã‚‹
        merged_segments = []
        cumulative_duration = 0

        for i, transcript_data in enumerate(transcripts):
            transcript = transcript_data['transcript']
            start_offset = cumulative_duration

            logger.info(f"Processing transcript {i+1}/{len(transcripts)}")
            logger.info(f"  Start offset: {start_offset:.1f}s")
            logger.info(f"  Duration: {transcript_data['duration']:.1f}s")

            segments_added = 0
            segments_skipped = 0

            if hasattr(transcript, 'segments') and transcript.segments:
                logger.info(f"  Found {len(transcript.segments)} segments in transcript {i+1}")

                for j, segment in enumerate(transcript.segments):
                    # segmentã®å‡¦ç†
                    if isinstance(segment, dict):
                        start = segment.get('start', 0)
                        end = segment.get('end', 0)
                        text = segment.get('text', '').strip()
                    else:
                        start = getattr(segment, 'start', 0)
                        end = getattr(segment, 'end', 0)
                        text = getattr(segment, 'text', '').strip()

                    # æ™‚åˆ»ã‚’è£œæ­£
                    adjusted_start = start + start_offset
                    adjusted_end = end + start_offset

                    # é‡è¤‡éƒ¨åˆ†ã®å‡¦ç†ï¼ˆæœ€åˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä»¥å¤–ï¼‰
                    skip_segment = False
                    if use_overlap_processing and i > 0:
                        # æ”¹å–„ã•ã‚ŒãŸé‡è¤‡å‡¦ç†: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã®ç›¸å¯¾æ™‚é–“ã§åˆ¤å®š
                        # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯2åˆ†(120ç§’) + 15ç§’é‡è¤‡ = 135ç§’
                        # é‡è¤‡éƒ¨åˆ†ã¯æœ€åˆã®15ç§’ãªã®ã§ã€15ç§’ä»¥é™ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã¿ä¿æŒ
                        if start < overlap_duration:
                            skip_segment = True
                            segments_skipped += 1
                            logger.debug(f"    Skipping segment {j+1} (overlap): {start:.1f}s < {overlap_duration:.1f}s")
                        else:
                            logger.debug(f"    Keeping segment {j+1} (beyond overlap): {start:.1f}s >= {overlap_duration:.1f}s")
                    else:
                        logger.debug(f"    Keeping segment {j+1} (first segment or overlap disabled): {start:.1f}s")

                    if not skip_segment:
                        merged_segments.append(TranscriptionSegment(
                            start=adjusted_start,
                            end=adjusted_end,
                            text=text
                        ))
                        segments_added += 1
                        logger.debug(f"    Added segment {j+1}: {adjusted_start:.1f}s-{adjusted_end:.1f}s")

            logger.info(f"  Segments added: {segments_added}, skipped: {segments_skipped}")

            # ç´¯ç©æ™‚é–“ã‚’æ›´æ–°ï¼ˆé‡è¤‡æœŸé–“ã‚’é™¤ãï¼‰
            if use_overlap_processing:
                if i < len(transcripts) - 1:  # æœ€å¾Œä»¥å¤–
                    cumulative_duration += transcript_data['duration'] - overlap_duration
                    logger.info(f"  Updated cumulative duration: {cumulative_duration:.1f}s (removed {overlap_duration:.1f}s overlap)")
                else:  # æœ€å¾Œ
                    cumulative_duration += transcript_data['duration']
                    logger.info(f"  Final cumulative duration: {cumulative_duration:.1f}s")
            else:
                # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: é‡è¤‡ã‚’è€ƒæ…®ã›ãšã«å˜ç´”ã«åŠ ç®—
                if i == 0:
                    cumulative_duration = transcript_data['duration']
                else:
                    # 2åˆ†é–“éš”ã§åˆ†å‰²ã—ã¦ã„ã‚‹ã®ã§ã€2åˆ†ãšã¤åŠ ç®—
                    cumulative_duration += 2 * 60  # 2åˆ† = 120ç§’
                logger.info(f"  Debug mode cumulative duration: {cumulative_duration:.1f}s")

        result = self._build_result(merged_segments)

        logger.info(f"Merge completed:")
        logger.info(f"  Total segments: {len(merged_segments)}")
        logger.info(f"  Total text length: {len(result.full_text)} characters")
        logger.info(f"  Final duration: {cumulative_duration:.1f}s ({cumulative_duration/60:.1f} minutes)")

        return result

    def _process_transcript(self, transcript) -> TranscriptionResult:
        """
        å˜ä¸€ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‡¦ç†
        """
        segments = []

        if hasattr(transcript, 'segments') and transcript.segments:
            for segment in transcript.segments:
                if isinstance(segment, dict):
                    start = segment.get('start', 0)
                    end = segment.get('end', 0)
                    text = segment.get('text', '').strip()
                else:
                    start = getattr(segment, 'start', 0)
                    end = getattr(segment, 'end', 0)
                    text = getattr(segment, 'text', '').strip()

                segments.append(TranscriptionSegment(
                    start=start,
                    end=end,
                    text=text
                ))

        return self._build_result(segments)

    def _build_result(self, segments) -> TranscriptionResult:
        """
        ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰TranscriptionResultã‚’æ§‹ç¯‰
        """
        full_text_parts = []

        for segment in segments:
            start_time = self._format_timestamp(segment.start)
            full_text_parts.append(f"ã€{start_time}ã€‘{segment.text}")

        if not full_text_parts:
            full_text_parts.append("ã€00:00:00ã€‘éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ãŒã§ãã¾ã›ã‚“ã§ã—ãŸ")

        full_text = "\n".join(full_text_parts)

        return TranscriptionResult(
            segments=segments,
            full_text=full_text
        )

    def _format_timestamp(self, seconds: float) -> str:
        """
        ç§’æ•°ã‚’HH:MM:SSå½¢å¼ã«å¤‰æ›
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
